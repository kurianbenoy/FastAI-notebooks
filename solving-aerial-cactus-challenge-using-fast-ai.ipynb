{"cells":[{"metadata":{},"cell_type":"markdown","source":"**About this challenge**\n\nTo assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the VIGIA project, which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery.\n\nIn this kernel we will be trying to solve this challenge using CNN through **fast.ai library**\n\n![Fastailogo](https://images.ctfassets.net/orgovvkppcys/5EShj6ZsQFERrNd/af53baa732ce18025c51c9268ffd037b/image.png?w=648&q=100)"},{"metadata":{},"cell_type":"markdown","source":"**Loading necessary libraries**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from fastai.vision import *\nfrom fastai import *\nimport os\nimport pandas as pd\nimport numpy as np\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir=\"../input/train/train\"\ntest_dir=\"../input/test/test\"\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv(\"../input/sample_submission.csv\")\ndata_folder = Path(\"../input\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analysing the given data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting the Data. **\n[reference](https://docs.fast.ai/vision.data.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = ImageList.from_df(test, path=data_folder/'test', folder='test')\n# Applying Data augmentation\ntrfm = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)\ntrain_img = (ImageList.from_df(train, path=data_folder/'train', folder='train')\n        .split_by_rand_pct(0.01)\n        .label_from_df()\n        .add_test(test_img)\n        .transform(trfm, size=128)\n        .databunch(path='.', bs=64, device= torch.device('cuda:0'))\n        .normalize(imagenet_stats)\n       )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training the data using appropriate model. We have used [densenet](https://pytorch.org/docs/stable/torchvision/models.html) here**"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(train_img, models.densenet161, metrics=[error_rate, accuracy])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the suitable learning rate**"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting the Learning Rate**"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now training the data based on suitable learning rate**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-02\nlearn.fit_one_cycle(3, slice(lr))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.has_cactus = preds.numpy()[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**References**\n* https://docs.fast.ai/\n* https://www.kaggle.com/kenseitrg/simple-fastai-exercise\n* https://www.kaggle.com/shahules/getting-started-with-cnn-and-vgg16\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
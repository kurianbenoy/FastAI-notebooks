{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install fastai2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time series Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai2.tabular.all import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_pickle('/kaggle/input/fastai-v3-rossman-data-clean/train_clean')\ntest = pd.read_pickle('/kaggle/input/fastai-v3-rossman-data-clean/test_clean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ncat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n    'SchoolHoliday_fw', 'SchoolHoliday_bw', 'Promo', 'SchoolHoliday']\n\ncont_vars = ['CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n   'AfterStateHoliday', 'BeforeStateHoliday']\n   \ndep_var = 'Sales'\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Sales'] = np.log(train[dep_var])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"procs = [FillMissing, Normalize, Categorify]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train), len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'].min(), train['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date'].min(), test['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = train['Date'][train['Date'] == train['Date'][len(test)]].index.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splits = (L(range(idx, len(train))), L(range(idx)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\npd.options.mode.chained_assignment=None\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to = TabularPandas(train, procs, cat_vars, cont_vars, dep_var, block_y=RegressionBlock(), \\\n                      splits=splits, inplace=True, reduce_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = to.dataloaders(bs=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling\n\n- TabularLearner"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_log_y = np.max(train['Sales'])*1.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_log_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_range = torch.tensor([0, max_log_y]); y_range","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = tabular_learner(dls, layers=[1000, 500], ps=[0.001, 0.01],\n                       embed_p=0.04, y_range=y_range, metrics=exp_rmspe,\n                       loss_func=MSELossFlat())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 5e-3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inferencing on the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export('myModel')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del learn\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = load_learner('myModel')\ndl = learn.dls.test_dl(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_test_preds = learn.get_preds(dl=dl)\nlearn.validate(dl=dl)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = np.exp(raw_test_preds[0]).numpy().T[0]\ntest['Sales'] = test_preds\ntest[['Id', \"Sales\"]] = test[['Id', 'Sales']].astype('int')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['Id', 'Sales']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[submission](submission.csv)"},{"metadata":{},"cell_type":"markdown","source":"## Permutation Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"class PermutationImportance():\n  \"Calculate and plot the permutation importance\"\n  def __init__(self, learn:Learner, df=None, bs=None):\n    \"Initialize with a test dataframe, a learner, and a metric\"\n    self.learn = learn\n    self.df = df\n    bs = bs if bs is not None else learn.dls.bs\n    if self.df is not None:\n      self.dl = learn.dls.test_dl(self.df, bs=bs)\n    else:\n      self.dl = learn.dls[1]\n    self.x_names = learn.dls.x_names.filter(lambda x: '_na' not in x)\n    self.na = learn.dls.x_names.filter(lambda x: '_na' in x)\n    self.y = dls.y_names\n    self.results = self.calc_feat_importance()\n    self.plot_importance(self.ord_dic_to_df(self.results))\n\n  def measure_col(self, name:str):\n    \"Measures change after column shuffle\"\n    col = [name]\n    if f'{name}_na' in self.na: col.append(name)\n    orig = self.dl.items[col].values\n    perm = np.random.permutation(len(orig))\n    self.dl.items[col] = self.dl.items[col].values[perm]\n    metric = learn.validate(dl=self.dl)[1]\n    self.dl.items[col] = orig\n    return metric\n\n  def calc_feat_importance(self):\n    \"Calculates permutation importance by shuffling a column on a percentage scale\"\n    print('Getting base error')\n    base_error = self.learn.validate(dl=self.dl)[1]\n    self.importance = {}\n    pbar = progress_bar(self.x_names)\n    print('Calculating Permutation Importance')\n    for col in pbar:\n      self.importance[col] = self.measure_col(col)\n    for key, value in self.importance.items():\n      self.importance[key] = (base_error-value)/base_error #this can be adjusted\n    return OrderedDict(sorted(self.importance.items(), key=lambda kv: kv[1], reverse=True))\n\n  def ord_dic_to_df(self, dict:OrderedDict):\n    return pd.DataFrame([[k, v] for k, v in dict.items()], columns=['feature', 'importance'])\n\n  def plot_importance(self, df:pd.DataFrame, limit=20, asc=False, **kwargs):\n    \"Plot importance with an optional limit to how many variables shown\"\n    df_copy = df.copy()\n    df_copy['feature'] = df_copy['feature'].str.slice(0,25)\n    df_copy = df_copy.sort_values(by='importance', ascending=asc)[:limit].sort_values(by='importance', ascending=not(asc))\n    ax = df_copy.plot.barh(x='feature', y='importance', sort_columns=True, **kwargs)\n    for p in ax.patches:\n      ax.annotate(f'{p.get_width():.4f}', ((p.get_width() * 1.005), p.get_y()  * 1.005))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = PermutationImportance(learn, tran.iloc[:1000], bs=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}